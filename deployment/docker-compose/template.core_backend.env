# If not set, uses default values defined in core_backend/app/**/config.py files.

#### ðŸ”’ Postgres variables -- change for production ############################
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=postgres

#### ðŸ”’ Admin user -- change for production ####################################
ADMIN_USERNAME="admin"
ADMIN_PASSWORD="fullaccess"
ADMIN_API_KEY="admin-key"

#### Admin user rate limits ###################################################
# ADMIN_CONTENT_QUOTA=1000
# ADMIN_API_DAILY_QUOTA=100

#### ðŸ”’ JWT -- change for production ###########################################
JWT_SECRET="jwt-secret"

#### Redis  -- change for production ##########################################
REDIS_HOST="redis://localhost:6379"
# For docker compose, use "redis://redis:6379"

#### ðŸ”’ LiteLLM Proxy Server -- change for production ##########################
LITELLM_ENDPOINT="http://localhost:4000"
LITELLM_API_KEY="update-embeddings-api-key"
# For docker compose, use "http://litellm_proxy:4000"

#### Variables for Huggingface embeddings container ###########################
# If on ARM, you need to build the embeddings image manually using
# `make build-embeddings-arm` from repository root and set the following variables
# EMBEDDINGS_IMAGE_NAME=text-embeddings-inference-arm
# PGVECTOR_VECTOR_SIZE=1024

#### Temporary folder for prometheus gunicorn multiprocess ####################
PROMETHEUS_MULTIPROC_DIR="/tmp"

#### Application-wide content limits ##########################################
# CHECK_CONTENT_LIMIT=True
# DEFAULT_CONTENT_QUOTA=50

#### Number of top content to return for /search. #############################
# N_TOP_CONTENT=5

#### Urgency detection variables ##############################################
# URGENCY_CLASSIFIER="cosine_distance_classifier"
# Choose between `cosine_distance_classifier` and `llm_entailment_classifier`

# URGENCY_DETECTION_MAX_DISTANCE=0.5
# Only used if URGENCY_CLASSIFIER=cosine_distance_classifier

# URGENCY_DETECTION_MIN_PROBABILITY=0.5
# Only used if URGENCY_CLASSIFIER=llm_entailment_classifier

#### LiteLLM tracing ##########################################################
LANGFUSE=False
